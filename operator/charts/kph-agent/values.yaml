# KPH Agent Configuration
# See https://github.com/henleda/kubernetes-policy-hub for documentation

# Global image configuration
# Override these to use your own registry (Docker Hub, GCR, ACR, etc.)
global:
  image:
    # Registry URL (e.g., docker.io, gcr.io, <account>.azurecr.io, <account>.dkr.ecr.<region>.amazonaws.com)
    registry: "docker.io"
    # Repository path (without registry prefix)
    repository: "policyhub/kph-agent"
    # Image tag
    tag: "latest"
    # Pull policy: Always, IfNotPresent, Never
    pullPolicy: "IfNotPresent"

  # Image pull secrets for private registries
  # Example: imagePullSecrets: [{name: "my-registry-secret"}]
  imagePullSecrets: []

# Agent configuration (required)
agent:
  # Cluster identification - provided by KPH SaaS
  clusterId: ""
  clusterName: ""
  organizationId: ""

  # Authentication token from KPH SaaS
  # Option 1: Provide token directly (less secure - visible in shell history)
  token: ""

  # Option 2: Use an existing secret (recommended for security)
  # Create the secret first: kubectl create secret generic kph-agent-token --from-literal=api-token=YOUR_TOKEN
  # Then set existingSecret to the secret name
  existingSecret: ""

  # KPH SaaS server URL
  serverUrl: "https://policy-hub-starter.vercel.app"

  # Policy sync interval in seconds
  syncInterval: 30

  # Heartbeat interval in seconds
  heartbeatInterval: 60

  # Log level: debug, info, warn, error
  logLevel: info

# Namespace for all components
namespace: kph-system

# Set to true if you want the chart to create the namespace
# Set to false (default) when using helm install --create-namespace
createNamespace: false

# Operator settings
operator:
  # Image override (uses global.image if not set)
  # To use a different image for operator, set these values
  image:
    # Leave empty to use global.image settings
    registry: ""
    repository: ""
    tag: ""
    pullPolicy: ""

  replicas: 1

  resources:
    requests:
      cpu: 100m
      memory: 64Mi
    limits:
      cpu: 500m
      memory: 256Mi

  # Node selection for multi-architecture support
  # Example for arm64: nodeSelector: { kubernetes.io/arch: arm64 }
  # Example for amd64: nodeSelector: { kubernetes.io/arch: amd64 }
  # Leave empty to schedule on any architecture (requires multi-arch images)
  nodeSelector: {}

  # Tolerations for scheduling on tainted nodes
  tolerations: []

  # Affinity rules for advanced scheduling
  affinity: {}

# Collector settings (telemetry collection via Hubble/Tetragon)
collector:
  enabled: true

  # Image override (uses global.image if not set)
  # To use a different image for collector, set these values
  image:
    # Leave empty to use global.image settings
    registry: ""
    repository: ""
    tag: ""
    pullPolicy: ""

  resources:
    requests:
      cpu: 100m
      memory: 512Mi
    limits:
      cpu: "1"
      memory: 2Gi

  # Node selection for multi-architecture support
  # The collector runs as a DaemonSet, so it schedules on all matching nodes
  # Example for arm64 only: nodeSelector: { kubernetes.io/arch: arm64 }
  # Leave empty to run on all nodes (requires multi-arch images)
  nodeSelector: {}

  # Additional tolerations (DaemonSet already tolerates all taints by default)
  tolerations: []

  # Affinity rules for advanced scheduling
  affinity: {}

# Telemetry settings
telemetry:
  enabled: true

  # Hubble integration
  hubble:
    enabled: true
    address: "hubble-relay.kube-system.svc.cluster.local:80"

  # Tetragon integration
  tetragon:
    enabled: false
    address: "unix:///var/run/tetragon/tetragon.sock"

  # Local storage settings
  storage:
    path: "/var/lib/policyhub/telemetry"
    retentionDays: 7
    maxStorageGb: 10

# Feature flags
features:
  policySync: true
  admissionWebhook: true
  auditLogging: true
  simulation: true
  validation: true

# Cluster metadata (optional)
cluster:
  provider: OTHER  # AWS, GCP, AZURE, ON_PREM, OTHER
  region: ""
  environment: DEVELOPMENT  # DEVELOPMENT, STAGING, PRODUCTION, TESTING
